{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Model Training and Comparison\n",
    "\n",
    "In this notebook, you'll build, train, and evaluate several regression models to predict CO2 emission per capita. We'll use preprocessing utilities from the `src/data_preprocessing.py` script for a clean workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import preprocessing utilities\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_preprocessing import load_data, train_test_split_processed\n",
    "\n",
    "# Load and preprocess data\n",
    "df = load_data('../data/carbon_emission_ml_dataset.csv')\n",
    "X_train, X_test, y_train, y_test, preprocessor, feature_names = train_test_split_processed(df)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "    'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return rmse, r2\n",
    "\n",
    "results = []"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Results Collection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train each model and record results\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    rmse, r2 = evaluate_model(model, X_test, y_test)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2\n",
    "    })"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df = pd.DataFrame(results).sort_values(by='RMSE')\n",
    "results_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Bar plot for visual comparison\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(results_df['Model'], results_df['RMSE'], color='skyblue')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE Comparison of Models')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance (Optional & Advanced)\n",
    "\n",
    "Let's examine feature importance for tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example: Feature importance for Random Forest\n",
    "rf = models['Random Forest']\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "imp_df = imp_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(imp_df['Feature'], imp_df['Importance'], color='orange')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Insights and Next Steps\n",
    "\n",
    "- Review which models performed best and why.\n",
    "- Examine which features are most important for predictions (see above).\n",
    "- Try tuning model hyperparameters for improved results.\n",
    "- Next: add more advanced evaluation, cross-validation, or deploy your best model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}